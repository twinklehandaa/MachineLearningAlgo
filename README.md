# Basics of Machine Learning

## 1. Data Preprocessing
* Handling missing data, encoding categorical data, splitting the dataset into training and testing data, feature scaling

## 2. Simple Linear Regression
* It models the relationship between a dependent variable and a single independent variable by fitting a linear equation to the observed data.

## 3. Multiple Linear Regression
* It is used to predict a continuous target variable based on the linear relationship between it and two or more predictor variables.

## 4. Logistic Regression
* It is used for binary classification tasks, i.e., it's used when you want to predict the probability of a data point belonging to one of two categories.

## 5. Decision Tree
* It is used for both classification and regression tasks, it recursively splits data based on features to create a tree-like structure that predicts outcomes based on decision rules.

## 6. Random Forest
* A random forest is a machine learning algorithm that combines the predictions of multiple decision trees to make more accurate predictions. Â  

## 7. KNN
* KNN classifies data points based on the classes of their k-nearest neighbors in the feature space.
  
## 8. Naives Bayes
* Naive Bayes is a classification technique that predicts the probability of a class based on prior knowledge of conditions related to that class, assuming that the presence of a particular feature in a class is unrelated to the presence of any other feature.
  
## 9. K-means Clustering
* K-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.

## 10. Hierarchial Clustering
* Hierarchical clustering builds a hierarchy of clusters by either merging similar clusters (agglomerative) or splitting existing clusters (divisive).
  
## 11. Principle Component Analysis (PCA)
* PCA finds new, uncorrelated variables (principal components) that capture the maximum variance in the data, thus reducing dimensionality.
  
## 12. Backpropagation
## 13. Performance Measure
